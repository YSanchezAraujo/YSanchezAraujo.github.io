<h1>Entropy is not entropy, it's entropy</h1>

Both in physics and information theory there is a term called entropy that refer to two different things. Sometimes
their meanings are conflated. I have not studied physcis so I will not attempt to define entropy there. However in the
realm of information theory, entropy deals with the concept of information. Information in turn is not associated 
directly with the typically definition of "knowledege", but rather with the notion of uncertainty. That is, an object
with high entropy has high uncertainty and thus - low probability. 
